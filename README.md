##  Време за предаване:
**7 календарни дни** считано от датата на изпращане на заданието.

---

## Задача 1: ETL Пайплайн
Изградете **ETL пайплайн**, който:
1. Извлича данни от **JSON файл**, съдържащ информация за фактури на клиенти, хостнат в GitHub.
2. Трансформира данните с помощта на **Python**.
3. Зарежда резултатите в **локални симулации на GCP услуги**:
   - **Cloud Storage** → локална директория (напр. `landing_zone/raw_telecom_data.json`)
   - **BigQuery** → използвайте **SQLite база данни** като симулация  

**Решението (кода) трябва да бъде върнато в GitHub.**

### Разяснения
- **Симулация на Cloud Storage**:  
  След изтегляне на JSON файла, запишете го в локална директория. Това ще играе ролята на *bucket*, където се появяват суровите данни.
- **Симулация на BigQuery**:  
  Използвайте **SQLite** като алтернатива на BigQuery.
- **Налични допълнителни пакети**:  
  `SkyShowtime, Storytel, HBO MAX, Deezer, VOYO, Bookmate, IZZi, Capital`
- **Налични роуминг пакети**:  
  `EU daily, EU weekly, EU monthly, Balkans, UK, World`

 Не е задължително да спазвате точно тези разяснения – може да предоставите и **алтернативно решение**.



##  Задача 2: Визуализация на процеси
С помощта на **draw.io** или подобен инструмент изградете диаграми за:
1. **ETL процеса от Задача 1** – как бихте го реализирали в **клауд среда**.
2. **MLOps процес**, който:
   - Подготвя данните за използване от **Data Science** екипа.
   - Осигурява **контрол на версиите**.
   - Автоматизира изпълнението в **продукционна среда**.
   - Включва **мониторинг** на задачите.



## Въпроси
При възникване на въпроси относно поставените задачи, **не се колебайте да се свържете с нас** – ще съдействаме с допълнителна информация!
